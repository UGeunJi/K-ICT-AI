## Convolutional Filter

- Convolutional Filter는 자동 특징 추출기(Feature Extractor)임
- CNN이 나오기 전에는 사람의 얼굴에서 특징을 만들어내는 과정을 직접 코딩해야 했는데 이제는 CNN이 이런 작업을 대신하기도 하고 특징 정보를 만들어 낼 수 있음
- 사람이 물체를 볼 때, 세밀하게 다 보는 것이 아니고 전반적이 shape, 특징을 봄. CNN의 원리임
- CNN은 2차원으로 데이터를 처리하기 때문에 일반적인 신경망 모형에 비해 유리

## Convolutional Neural Network

- CNN 처리 과정은 이미지로부터 Feature를 Extraction하는 과정과 Feature를 이용하여 딥러닝을 수행하는 과정으로 나눠진다.
- Feature Extraction은 Convolutional Layer를 이용하여 이미지의 특징을 추출하고 Pooling Layer에서 대표값을 만드는 과정을 반복하여 특징을 단순화해간다.
- 단순화된 특징은 이미지를 구별할 수 있는 간결한 특징만 남고 판별에 도움이 되지 않는 자세한 이미지 정보는 삭제된다.
- CNN은 사람이 이미지를 인식하는 과정과 유사하다. 사람이 이미지를 볼 때, 이미지 전체를 학습하는 것이 아니라 몇 개의 특징을 학습한다고 한다.

![image](https://user-images.githubusercontent.com/84713532/233857489-fc7c6a16-0cc2-4f62-99ce-47b4e062c526.png)


필터는 5X5X3개의 정보를 하나의 값으로 변환하여 정보를 축약한다.

![image](https://user-images.githubusercontent.com/84713532/233857856-fe6abd26-2404-4792-8be1-ad8369e73b46.png)

![image](https://user-images.githubusercontent.com/84713532/233857984-7521f52f-b5e7-439d-a169-9eabf8636bc0.png)

ReLU(Max Pooling)

![image](https://user-images.githubusercontent.com/84713532/233858030-d1cf5aaf-9c7e-491d-b73a-2bdccc5fb9be.png)

#### 정보손실 - 주요 정보만 남는다.

![image](https://user-images.githubusercontent.com/84713532/233858089-1a318cf3-c6fb-4144-8118-03e27accebee.png)

결과적으로 이런 결과 예측을 할 수 있게 됨

![image](https://user-images.githubusercontent.com/84713532/233858755-702b2d05-6696-4d22-b103-b3ffbd855322.png)

#### MNIST, Fashion MNIST, CIFAR10 등 유명한 예시가 있다.

### Fashion MNIST Convolutional Neural Network Example

![image](https://user-images.githubusercontent.com/84713532/233858874-8457a8b4-bb61-4038-9fed-87b2e3b284a9.png)

- 모형에서 사용되는 총 parameter는 412,778개이고 구글 colab에서 47초 만에 학습을 완료
- 정확도는 92%를 기록

### CIFAR10 Convolutional Neural Network Example

CIFAR10 자료는 Canadian Institute for Advanced Research에서 만든 airplane, car, bird, cat, deer, dog, frog, horse, ship, truck 이미지임
Fashion Mnist와 다르게 배경이 존재하고 이미지 크기는 32X32X3임

$$Kernel ~~ Regularization ~~~~ min(||Y - X(\theta)||^2_2 + \lambda ||\theta||^2_2$$

#### Ridge Regularization

- 실제값인 Y와 쎄타를 넣고 훈련시킨 결과값인 X와의 차이의 제곱의 합인 SSE에 쎄타들의 제곱의 합을 작게 만들고자 함
- dropout과 같은 방식임

$$\hat{\beta}^ridge = argmin \displaystyle\sum_{i=1}{n}{(y_i - x_i \beta)^2}$$

$$subject ~~ to ~~ \displaystyle\sum_{j=1}{p}{\beta^2_j ≤ t}$$

- 32 conv -> 64 conv -> 128 conv 형식으로 Convolution Layer를 추가 확장하고 Batch Normalization과 Kernel Regularization을 추가한 결과, 74%에서 84%의 정확도 향상
- Image Generator를 추가하고 Epoch를 대폭 늘려 수행한 결과, 88%로 4% 증가

---

## Transfer Learning

- VGGNet, GoogleNet, ResNet은 Transfer Learning에 주로 사용되는 pre-trained CNN임

![image](https://user-images.githubusercontent.com/84713532/233859870-a2d9a419-a38a-4d54-addb-caecae94e810.png)

- 전이학습은 이미 잘 만들어진 학습모형을 계승해서 해당 모델과 유사한 문제를 해결하고자 하는 방법임
- pre-trained Network로는 Xception, 구글 Inception V3, ResNet50, VGG16, VGG19 등이 있음

#### VGG16 전이학습 예시

```py
conv_base = VGG16(weighs='imagenet', include_top=False, input_shape=(150, 150, 3))

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
conv_base.trainable = False
```

- include_top은 VGG 모형의 FC Layer를 사용하지 않는다는 의미
- conv_base.trainable은 학습과정에서 VGG16 모형의 파라미터를 갱신할지 여부를 지정 - 전이학습에서는 반드시 False임
