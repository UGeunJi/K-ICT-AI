# 시계열 모형

#### RNN은 기존의 신경망 모형을 확장하여 Time Series Forecasting이 가능하도록 만든 모형이다.

- 예를 들어, 현재 내 모습은 "과거의 내 모습 + 현재의 상황"에 의해 만들어진다는 상식적인 접근이다.
- 이렇게 시간에 따라 변하는 데이터를 시계열 데이터라고 하고 순서가 중요하며 간격이 있어야 한다.

### 시계열을 설명하는 가장 간단한 모형은 아래와 같다.

- 아래 첫 번째 모형은 AR(1) 모형이라고 한다. AR은 Autoregressive의 약어다.
- 두 번째 모형은 ARMA(1, 1) 모형이다.
- 통계학에서 아래와 같은 형태를 확장하여 ARIMA 모형이라고 하는데 이는 선형모형임을 알 수 있다.

$$Y_t = \phi Y_{t-1} + \epsilon_t$$

$$Y_t = \phi Y_{t-1} - \theta{\epsilon_{t-1}} + \epsilon_t$$

# RNN

- Simple RNN 모형

![image](https://github.com/UGeunJi/K-ICT_Analysis-Infra-Application_AI/assets/84713532/854b3ec4-351d-4f2b-995c-05db835e9d70)

- 모형은 입력과 히든 레이어 그리고 출력으로 나눠진다. 히든 레이어가 존재하고 비선형 활성함수를 사용한 비선형 모형이다.
- 그림에서 순환하는 모양의 화살표가 있는데 이 때문에 순환(Recurrent) 신경망이라고 부른다.
- 순환 과정은 우측 그림과 같이 펼칠 수 있다. 즉, t 시점의 h는 t 시점의 x와 t-1 시점의 h를 만든다.

$$여기서 ~~ h_t는 ~~ 정답 ~ y_t의 ~~ 차이를 ~~ Cost ~ 함수로 ~~ 만들어 ~~ 이를 ~~ 최소화하는 ~~ Weight를 ~~ 만들어주면 ~~ RNN ~ 모형이 ~~ 완성되는 ~~ 것이다.$$

$$y_t에 ~~ 대한 ~~ 추정은 ~~ 아래의 ~~ 식으로 ~~ 이루어진다.$$

$$h_t = f(h_{t-1}, ~ x_t) = tanh(W_{hh}h{t-1} + W_{xh}x_t)$$

$$y_t = W_{hy}h_t

활성함수 f()는 tanh or ReLU 함수를 사용한다.

### RNN의 다양한 변신

![image](https://github.com/UGeunJi/K-ICT_Analysis-Infra-Application_AI/assets/84713532/8679fd11-87f4-43c3-a9ae-bf3a4f12999d)

- RNN에서 Hidden Layer를 여러 개 사용하면 Multiple Layer RNN이 된다.

# char RNN
























